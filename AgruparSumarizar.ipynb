{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e513538c-cec7-4308-a475-238d5deb3e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----+----+-------+--------+--------+\n",
      "|CODMUNRES| DTOBITO|IDADE|SEXO|RACACOR|CAUSABAS|TIPOBITO|\n",
      "+---------+--------+-----+----+-------+--------+--------+\n",
      "|   292720| 2012023|  457|   2|      4|    J980|       2|\n",
      "|   292720| 5012023|  482|   2|      2|    I500|       2|\n",
      "|   292720| 7012023|  452|   2|      4|    C220|       2|\n",
      "|   292720| 8012023|  456|   2|      4|    W789|       2|\n",
      "|   292720|10012023|  468|   1|      4|    X954|       2|\n",
      "+---------+--------+-----+----+-------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import(\n",
    "    when, col, substring, expr, \n",
    "    to_date, year, sum, count, lit,\n",
    "    regexp_replace, lpad, length,\n",
    "    month, count\n",
    ")\n",
    "spark = SparkSession.builder.appName(\"agrupar-sumarizar\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.maxNumRows\", 20) \\\n",
    "    .getOrCreate()\n",
    "df = spark.read.csv(\"curso-analise-de-dados/dados/sim_salvador_2023.csv\",\n",
    "                    header=True,\n",
    "                    inferSchema=True\n",
    ")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f9f9ad-ad89-4ef8-a625-fb85d7177153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------------+\n",
      "| ano|mes|obitos_totais|\n",
      "+----+---+-------------+\n",
      "|2023|  1|           23|\n",
      "|2023|  2|           15|\n",
      "|2023|  3|           14|\n",
      "|2023|  4|           22|\n",
      "|2023|  5|           30|\n",
      "|2023|  6|           25|\n",
      "|2023|  7|           20|\n",
      "|2023|  8|           20|\n",
      "|2023|  9|           22|\n",
      "|2023| 10|           20|\n",
      "|2023| 11|           19|\n",
      "|2023| 12|           31|\n",
      "+----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resumo funcional Esse código:\n",
    "# Corrige o formato da data de óbito (DTOBITO).\n",
    "# Converte o campo para um tipo de data válido.\n",
    "# Cria uma coluna derivada com o ano do óbito, facilitando análises temporais.\n",
    "# DTOBITO com date e ano_obito\n",
    "df = df.withColumn(\n",
    "    \"DTOBITO_clean\", \n",
    "    #Converte a coluna DTOBITO para string.\n",
    "    # Garante que ela tenha exatamente 8 caracteres, preenchendo com zeros à esquerda quando necessário.\n",
    "    lpad(col(\"DTOBITO\").cast(\"string\"), 8, \"0\")\n",
    ").withColumn(\n",
    "    # data no formato ddMMyyyy precisam ter 8 dígitos.\n",
    "    # Exemplo:\n",
    "    # 1012023 → 01012023\n",
    "    # 1122022 → 01122022\n",
    "    # conversão para o tipo date\n",
    "    \"DTOBITO_dt\", \n",
    "    # Converte a coluna DTOBITO_clean de string para o tipo Date do Spark.\n",
    "    # Usa explicitamente o formato ddMMyyyy.\n",
    "    # DTOBITO_dt passa a ser uma data válida, permitindo operações temporais (filtros, agrupamentos, etc.).\n",
    "    to_date(col(\"DTOBITO_clean\"), \"ddMMyyyy\")\n",
    ").withColumn(\n",
    "    # Extrai o ano da data de óbito.\n",
    "    # Cria a coluna ano_obito como um inteiro.\n",
    "    # Exemplo:\n",
    "    # 2023-01-01 → 2023\n",
    "    \"ano_obito\", \n",
    "    year(col(\"DTOBITO_dt\"))\n",
    ")\n",
    "df_obitos_por_mes = df \\\n",
    "    .groupBy(year(\"DTOBITO_dt\").alias(\"ano\"),\n",
    "            month(\"DTOBITO_dt\").alias(\"mes\")) \\\n",
    "    .agg(count(\"*\").alias(\"obitos_totais\")) \\\n",
    "    .orderBy(\"ano\",\"mes\")\n",
    "df_obitos_por_mes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cabc2f-4175-47b0-9c4e-fad6cde2c360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark_tutorial)",
   "language": "python",
   "name": "pyspark_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
