{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552139bd-5bd5-43b0-b239-12a27bf3e1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/30 20:03:12 WARN Utils: Your hostname, mauro-lucio resolves to a loopback address: 127.0.1.1; using 192.168.0.104 instead (on interface enp1s0)\n",
      "25/12/30 20:03:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/30 20:03:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|SEXO|count|\n",
      "+----+-----+\n",
      "|   1|  150|\n",
      "|   2|  111|\n",
      "+----+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|   GENERO|count|\n",
      "+---------+-----+\n",
      "|Masculino|  150|\n",
      "| Feminino|  111|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+--------+-----+----+-------+--------+--------+---------+\n",
      "|CODMUNRES| DTOBITO|IDADE|SEXO|RACACOR|CAUSABAS|TIPOBITO|   GENERO|\n",
      "+---------+--------+-----+----+-------+--------+--------+---------+\n",
      "|   292720| 2012023|  457|   2|      4|    J980|       2| Feminino|\n",
      "|   292720| 5012023|  482|   2|      2|    I500|       2| Feminino|\n",
      "|   292720| 7012023|  452|   2|      4|    C220|       2| Feminino|\n",
      "|   292720| 8012023|  456|   2|      4|    W789|       2| Feminino|\n",
      "|   292720|10012023|  468|   1|      4|    X954|       2|Masculino|\n",
      "+---------+--------+-----+----+-------+--------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- CODMUNRES: integer (nullable = true)\n",
      " |-- DTOBITO: integer (nullable = true)\n",
      " |-- IDADE: integer (nullable = true)\n",
      " |-- SEXO: integer (nullable = true)\n",
      " |-- RACACOR: string (nullable = true)\n",
      " |-- CAUSABAS: string (nullable = true)\n",
      " |-- TIPOBITO: integer (nullable = true)\n",
      " |-- GENERO: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    when, col, substring, expr,\n",
    "    to_date, year, sum, count,\n",
    "    lit, regexp_replace, lpad, length\n",
    ")\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"sim-salvador\") \\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.maxNumRows\", 20) \\\n",
    "    .getOrCreate()\n",
    "df = spark.read.csv(\n",
    "    \"curso-analise-de-dados/dados/sim_salvador_2023.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"GENERO\",\n",
    "    when(col(\"SEXO\")   == 1, \"Masculino\")\n",
    "     .when(col(\"SEXO\") == 2, \"Feminino\")\n",
    "     .when(col(\"SEXO\") == 0, \"Ignorado\")\n",
    "     .otherwise(None)  # NA_character_\n",
    ")  # when/otherwise é o análogo ao case_when.[web:54]\n",
    "df.groupBy(\"SEXO\").count().orderBy(\"count\", ascending=False).show()\n",
    "df.groupBy(\"GENERO\").count().orderBy(\"count\", ascending=False).show()\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97df0671-790f-440a-a869-6fcb9e9116d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|IDADE|tipo_idade|idade|\n",
      "+-----+----------+-----+\n",
      "|57   |4         |57   |\n",
      "|82   |4         |82   |\n",
      "|52   |4         |52   |\n",
      "|56   |4         |56   |\n",
      "|68   |4         |68   |\n",
      "|39   |4         |39   |\n",
      "|89   |4         |89   |\n",
      "|81   |4         |81   |\n",
      "|71   |4         |71   |\n",
      "|83   |4         |83   |\n",
      "+-----+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----+----------+-----+----------+\n",
      "|IDADE|tipo_idade|idade|idade_anos|\n",
      "+-----+----------+-----+----------+\n",
      "|   57|         4|   57|        57|\n",
      "|   82|         4|   82|        82|\n",
      "|   52|         4|   52|        52|\n",
      "|   56|         4|   56|        56|\n",
      "|   68|         4|   68|        68|\n",
      "|   39|         4|   39|        39|\n",
      "|   89|         4|   89|        89|\n",
      "|   81|         4|   81|        81|\n",
      "|   71|         4|   71|        71|\n",
      "|   83|         4|   83|        83|\n",
      "+-----+----------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+--------+-------------+----------+---------+\n",
      "|DTOBITO |DTOBITO_clean|DTOBITO_dt|ano_obito|\n",
      "+--------+-------------+----------+---------+\n",
      "|2012023 |02012023     |2023-01-02|2023     |\n",
      "|5012023 |05012023     |2023-01-05|2023     |\n",
      "|7012023 |07012023     |2023-01-07|2023     |\n",
      "|8012023 |08012023     |2023-01-08|2023     |\n",
      "|10012023|10012023     |2023-01-10|2023     |\n",
      "|10012023|10012023     |2023-01-10|2023     |\n",
      "|11012023|11012023     |2023-01-11|2023     |\n",
      "|12012023|12012023     |2023-01-12|2023     |\n",
      "|16012023|16012023     |2023-01-16|2023     |\n",
      "|17012023|17012023     |2023-01-17|2023     |\n",
      "+--------+-------------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------+-----+\n",
      "|ano_obito|count|\n",
      "+---------+-----+\n",
      "|     2023|  261|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+---------+-----+\n",
      "|   GENERO|ano_obito|count|\n",
      "+---------+---------+-----+\n",
      "| Feminino|     2023|  111|\n",
      "|Masculino|     2023|  150|\n",
      "+---------+---------+-----+\n",
      "\n",
      "root\n",
      " |-- CODMUNRES: integer (nullable = true)\n",
      " |-- DTOBITO: integer (nullable = true)\n",
      " |-- idade: string (nullable = true)\n",
      " |-- SEXO: integer (nullable = true)\n",
      " |-- RACACOR: string (nullable = true)\n",
      " |-- CAUSABAS: string (nullable = true)\n",
      " |-- TIPOBITO: integer (nullable = true)\n",
      " |-- GENERO: string (nullable = true)\n",
      " |-- tipo_idade: string (nullable = true)\n",
      " |-- idade_anos: integer (nullable = true)\n",
      " |-- DTOBITO_clean: string (nullable = true)\n",
      " |-- DTOBITO_dt: date (nullable = true)\n",
      " |-- ano_obito: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/30 20:03:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+------------------+-------------------+------------------+--------+--------+---------+-------------------+------------------+--------------------+---------+\n",
      "|summary|CODMUNRES|             DTOBITO|             idade|               SEXO|           RACACOR|CAUSABAS|TIPOBITO|   GENERO|         tipo_idade|        idade_anos|       DTOBITO_clean|ano_obito|\n",
      "+-------+---------+--------------------+------------------+-------------------+------------------+--------+--------+---------+-------------------+------------------+--------------------+---------+\n",
      "|  count|      261|                 261|               261|                261|               261|     261|     261|      261|                261|               261|                 261|      261|\n",
      "|   mean| 292720.0|1.6828153268199235E7| 66.03065134099617| 1.4252873563218391|  3.21900826446281|    NULL|     2.0|     NULL| 3.9731800766283527| 66.70114942528735|1.6828153268199235E7|   2023.0|\n",
      "| stddev|      0.0|   9098146.766400555|22.944896767060122|0.49533634046542185|1.2346863831199022|    NULL|     0.0|     NULL|0.30892033162911137|22.678920206893956|   9098146.766400555|      0.0|\n",
      "|    min|   292720|             1032023|                00|                  1|                 1|    A021|       2| Feminino|                  1|                 0|            01032023|     2023|\n",
      "|    max|   292720|            31122023|                99|                  2|                NA|    Y350|       2|Masculino|                  5|               102|            31122023|     2023|\n",
      "+-------+---------+--------------------+------------------+-------------------+------------------+--------+--------+---------+-------------------+------------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extrair tipo_idade e idade (str_sub equivalente)\n",
    "df = df.withColumn(\"tipo_idade\", substring(col(\"IDADE\").cast(\"string\"), 1, 1)) \\\n",
    "        .withColumn(\"idade\", substring(col(\"IDADE\").cast(\"string\"), 2, 100))\n",
    "df.select(\"IDADE\", \"tipo_idade\", \"idade\").show(10, truncate=False)\n",
    "\n",
    "# idade_anos com case_when\n",
    "df = df.withColumn(\n",
    "    \"idade_anos\",\n",
    "    when(col(\"tipo_idade\").cast(\"int\") <= 3, 0)\n",
    "    .when(col(\"tipo_idade\") == \"4\", col(\"idade\").cast(\"int\"))\n",
    "    .when(col(\"tipo_idade\") == \"5\", (100 + col(\"idade\").cast(\"int\")))\n",
    "    .otherwise(None)\n",
    ")\n",
    "df.select(\"IDADE\", \"tipo_idade\", \"idade\", \"idade_anos\").show(10)\n",
    "\n",
    "# DTOBITO com date e ano_obito\n",
    "df = df.withColumn(\n",
    "    \"DTOBITO_clean\", \n",
    "    lpad(col(\"DTOBITO\").cast(\"string\"), 8, \"0\")\n",
    ").withColumn(\n",
    "    \"DTOBITO_dt\", \n",
    "    to_date(col(\"DTOBITO_clean\"), \"ddMMyyyy\")\n",
    ").withColumn(\n",
    "    \"ano_obito\", \n",
    "    year(col(\"DTOBITO_dt\"))\n",
    ")\n",
    "\n",
    "df.select(\"DTOBITO\", \"DTOBITO_clean\", \"DTOBITO_dt\", \"ano_obito\").show(10, truncate=False)\n",
    "\n",
    "# contagens finais\n",
    "df.groupBy(\"ano_obito\").count().orderBy(\"ano_obito\").show()\n",
    "df.groupBy(\"GENERO\", \"ano_obito\").count().orderBy(\"ano_obito\", \"GENERO\").show()\n",
    "\n",
    "# Schema (equivalente a glimpse)\n",
    "df.printSchema()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d29e53-9cae-4e3d-a4e0-03cac3df7a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyspark_tutorial)",
   "language": "python",
   "name": "pyspark_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
